{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8f4eac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\phalg\\anaconda3\\envs\\env2\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.66.2\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba4c54ec",
   "metadata": {},
   "source": [
    "### Make Event and  IOU filtered corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ff51538",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26496\\1821439895.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;31m# events for ILPCR dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;31m# standard corpus, with citations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m \u001b[0mconvert_segment_dict_to_events_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../segment_dictionaries/ilpcr_processed/ilpcr/test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'./corpus/ik_test_events'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[0mconvert_segment_dict_to_events_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../segment_dictionaries/ilpcr_processed/ilpcr/train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'./corpus/ik_train_events'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26496\\1821439895.py\u001b[0m in \u001b[0;36mconvert_segment_dict_to_events_dataset\u001b[1;34m(segment_dir, out_path)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mout_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34mf'/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msegment_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msegment_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msegment_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34mf'/{file}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "import os, sys\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "def convert_segment_dict_to_events_dataset(segment_dir, out_path):\n",
    "    if out_path[-1] != \"/\":\n",
    "        out_path = out_path + f'/'\n",
    "\n",
    "    assert(os.path.isdir(segment_dir))\n",
    "    for file in os.listdir(segment_dir):\n",
    "        file = segment_dir + f'/{file}'\n",
    "        if \"query\" in file :\n",
    "            query_events = file\n",
    "            with open(query_events, 'rb') as f:\n",
    "                query_events = pkl.load(f)\n",
    "                query_events = query_events['dict_query']\n",
    "\n",
    "        elif \"candidate\" in file :\n",
    "            candidate_events = file\n",
    "            with open(candidate_events, 'rb') as f:\n",
    "                candidate_events = pkl.load(f)\n",
    "                candidate_events = candidate_events['dict_candidate']\n",
    "\n",
    "    # with open(f'./temp.txt', 'w+') as f:\n",
    "    #     print(candidate_events, file = f)\n",
    "\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "    os.makedirs(out_path + 'query/', exist_ok=True)\n",
    "    os.makedirs(out_path + 'candidate/', exist_ok=True)\n",
    "\n",
    "    for query_num in query_events.keys():\n",
    "        text = \" \".join(query_events[query_num])\n",
    "        temp_path = out_path + f'query/{query_num:010d}.txt'\n",
    "        with open(temp_path, 'w') as f:\n",
    "            f.write(text)\n",
    "\n",
    "    for candidate_num in candidate_events.keys():\n",
    "        text = \" \".join(candidate_events[candidate_num])\n",
    "        temp_path = out_path + f'candidate/{candidate_num:010d}.txt'\n",
    "        with open(temp_path, 'w') as f:\n",
    "            f.write(text)\n",
    "\n",
    "    return \n",
    "\n",
    "def convert_segment_dict_to_iouf_dataset(segment_dir, out_path):\n",
    "    if out_path[-1] != \"/\":\n",
    "        out_path = out_path + f'/'\n",
    "\n",
    "    assert(os.path.isdir(segment_dir))\n",
    "    for file in os.listdir(segment_dir):\n",
    "        file = segment_dir + f'/{file}'\n",
    "        if \"IOU\" not in file :\n",
    "            continue\n",
    "\n",
    "        with open(file, 'rb') as f: # single file contains query and candidate corpus\n",
    "            _ = pkl.load(f) \n",
    "        query_events = _['dict_query']\n",
    "        candidate_events = _['dict_candidate']\n",
    "\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "    os.makedirs(out_path + 'query/', exist_ok=True)\n",
    "    os.makedirs(out_path + 'candidate/', exist_ok=True)\n",
    "\n",
    "    for query_num in query_events.keys():\n",
    "        text = \" \".join(query_events[query_num])\n",
    "        temp_path = out_path + f'query/{query_num:010d}.txt'\n",
    "        with open(temp_path, 'w') as f:\n",
    "            f.write(text)\n",
    "\n",
    "    for candidate_num in candidate_events.keys():\n",
    "        text = \" \".join(candidate_events[candidate_num])\n",
    "        temp_path = out_path + f'candidate/{candidate_num:010d}.txt'\n",
    "        with open(temp_path, 'w') as f:\n",
    "            f.write(text)\n",
    "\n",
    "    return \n",
    "\n",
    "# events for ILPCR dataset \n",
    "# standard corpus, with citations\n",
    "convert_segment_dict_to_events_dataset('../segment_dictionaries/ilpcr_processed/ilpcr/test', './corpus/ik_test_events')\n",
    "convert_segment_dict_to_events_dataset('../segment_dictionaries/ilpcr_processed/ilpcr/train', './corpus/ik_train_events')\n",
    "\n",
    "# without citations\n",
    "convert_segment_dict_to_events_dataset('../segment_dictionaries/ilpcr_woc_processed/ilpcr_woc/test', './corpus/sentence_removed/ik_test_events')\n",
    "convert_segment_dict_to_events_dataset('../segment_dictionaries/ilpcr_woc_processed/ilpcr_woc/train', './corpus/sentence_removed/ik_train_events')\n",
    "\n",
    "# # events for COLIEE2021 dataset\n",
    "convert_segment_dict_to_events_dataset('../segment_dictionaries/coliee21_processed/coliee21/test', './corpus/COLIEE2021_test_events')\n",
    "convert_segment_dict_to_events_dataset('../segment_dictionaries/coliee21_processed/coliee21/train', './corpus/COLIEE2021_train_events')\n",
    "\n",
    "# iouf corpus for ILPCR dataset\n",
    "convert_segment_dict_to_iouf_dataset('../segment_dictionaries/ilpcr_processed/ilpcr/test', './corpus/ik_test_iouf')\n",
    "convert_segment_dict_to_iouf_dataset('../segment_dictionaries/ilpcr_processed/ilpcr/train', './corpus/ik_train_iouf')\n",
    "convert_segment_dict_to_iouf_dataset('../segment_dictionaries/ilpcr_woc_processed/ilpcr_woc/test', './corpus/sentence_removed/ik_test_iouf')\n",
    "convert_segment_dict_to_iouf_dataset('../segment_dictionaries/ilpcr_woc_processed/ilpcr_woc/train', './corpus/sentence_removed/ik_train_iouf')\n",
    "\n",
    "# iouf corpus for COLIEE2021 dataset\n",
    "convert_segment_dict_to_iouf_dataset('../segment_dictionaries/coliee21_processed/coliee21/test', './corpus/COLIEE2021_test_iou_filtered/')\n",
    "convert_segment_dict_to_iouf_dataset('../segment_dictionaries/coliee21_processed/coliee21/train', './corpus/COLIEE2021_train_iou_filtered/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f295177",
   "metadata": {},
   "source": [
    "### Make atomic events corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0f9bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_segment_dict_to_atomic_events_dataset(segment_dir, out_path):\n",
    "    if out_path[-1] != \"/\":\n",
    "        out_path = out_path + f'/'\n",
    "\n",
    "    assert(os.path.isdir(segment_dir))\n",
    "    for file in os.listdir(segment_dir):\n",
    "        file = segment_dir + f'/{file}'\n",
    "        if \"query\" in file :\n",
    "            query_events = file\n",
    "            with open(query_events, 'rb') as f:\n",
    "                query_events = pkl.load(f)\n",
    "                query_events = query_events['dict_query']\n",
    "\n",
    "        elif \"candidate\" in file :\n",
    "            candidate_events = file\n",
    "            with open(candidate_events, 'rb') as f:\n",
    "                candidate_events = pkl.load(f)\n",
    "                candidate_events = candidate_events['dict_candidate']\n",
    "\n",
    "    token_dict = {}\n",
    "    counter=0\n",
    "    for query in query_events:\n",
    "        for event in query_events[query]:\n",
    "            if event not in token_dict:\n",
    "                token_dict[event] = counter\n",
    "                counter+=1\n",
    "\n",
    "    for candidate in candidate_events:\n",
    "        for event in candidate_events[candidate]:\n",
    "            if event not in token_dict:\n",
    "                token_dict[event] = counter\n",
    "                counter+=1\n",
    "\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "    os.makedirs(out_path + 'query/', exist_ok=True)\n",
    "    os.makedirs(out_path + 'candidate/', exist_ok=True)\n",
    "\n",
    "    for query_num in query_events.keys():\n",
    "        text = \". \".join([str(token_dict[i]) for i in query_events[query_num]])\n",
    "        temp_path = out_path + f'query/{query_num:010d}.txt'\n",
    "        with open(temp_path, 'w') as f:\n",
    "            f.write(text)\n",
    "\n",
    "    for candidate_num in candidate_events.keys():\n",
    "        text = \". \".join([str(token_dict[i]) for i in candidate_events[candidate_num]])\n",
    "        temp_path = out_path + f'candidate/{candidate_num:010d}.txt'\n",
    "        with open(temp_path, 'w') as f:\n",
    "            f.write(text)\n",
    "    \n",
    "    return\n",
    "\n",
    "# Atomic event corpus for ILPCR\n",
    "convert_segment_dict_to_atomic_events_dataset('../segment_dictionaries/ilpcr_processed/ilpcr/test', './corpus/ik_test_atomic')\n",
    "convert_segment_dict_to_atomic_events_dataset('../segment_dictionaries/ilpcr_processed/ilpcr/train', './corpus/ik_train_atomic')\n",
    "convert_segment_dict_to_atomic_events_dataset('../segment_dictionaries/ilpcr_woc_processed/ilpcr_woc/test', './corpus/sentence_removed/ik_test_atomic')\n",
    "convert_segment_dict_to_atomic_events_dataset('../segment_dictionaries/ilpcr_woc_processed/ilpcr_woc/train', './corpus/sentence_removed/ik_train_atomic')\n",
    "\n",
    "# Atomic event corpus for COLIEE2021 dataset\n",
    "convert_segment_dict_to_atomic_events_dataset('../segment_dictionaries/coliee21_processed/coliee21/test', './corpus/COLIEE2021_test_atomic')\n",
    "convert_segment_dict_to_atomic_events_dataset('../segment_dictionaries/coliee21_processed/coliee21/train', './corpus/COLIEE2021_train_atomic')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2",
   "language": "python",
   "name": "env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
